{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from util_0704_ch import *\n",
    "from myalgorithm_0801_1 import algorithm\n",
    "\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 내용\n",
    "\n",
    "- 3 주문 번들이 묶인 형태 파악해서 번들 가능성 확인시 불필요한 탐색 조합을 발견하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트케이스 하나 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rider([BIKE, 5.291005291005291, 100, 60, 5000, 120, 40])\n",
      "Rider([WALK, 1.3227513227513228, 70, 30, 5000, 120, 60])\n",
      "Rider([CAR, 4.2328042328042335, 200, 100, 5000, 180, 200])\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# problem_file = r'C:\\Users\\hsh80\\Desktop\\LG CNS\\stage1_problems\\STAGE1_5.json'\n",
    "problem_file = '../alg_test_problems_20240429/TEST_K200_2.json'\n",
    "\n",
    "with open(problem_file, 'r') as f:\n",
    "    prob = json.load(f)\n",
    "\n",
    "K = prob['K']\n",
    "ALL_RIDERS = [Rider(rider_info) for rider_info in prob['RIDERS']]\n",
    "\n",
    "for v in ALL_RIDERS:\n",
    "    print(v)\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3310.4569999999994"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ------------------- 초기 상태 할당 코드 -------------------------\n",
    "\n",
    "with open(problem_file, 'r') as f:\n",
    "    prob = json.load(f)\n",
    "\n",
    "K = prob['K']\n",
    "\n",
    "ALL_ORDERS = [Order(order_info) for order_info in prob['ORDERS']]\n",
    "ALL_RIDERS = [Rider(rider_info) for rider_info in prob['RIDERS']]\n",
    "\n",
    "DIST = np.array(prob['DIST'])\n",
    "for r in ALL_RIDERS:\n",
    "    r.T = np.round(DIST/r.speed + r.service_time).astype(int)\n",
    "\n",
    "inf = float('inf')\n",
    "\n",
    "car_rider = [rider for rider in ALL_RIDERS if rider.type == 'CAR'][0]\n",
    "bike_rider = [rider for rider in ALL_RIDERS if rider.type == 'BIKE'][0]\n",
    "walk_rider = [rider for rider in ALL_RIDERS if rider.type == 'WALK'][0]\n",
    "\n",
    "init_availables = [rider.available_number for rider in ALL_RIDERS]\n",
    "\n",
    "## ------------------  크루스칼 함수   -----------------------------\n",
    "\n",
    "def kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, order_count_upper_limit, avg_method, all_bundles, default_get_dist_function):\n",
    "    def find(v):\n",
    "        while v != parent[v]:\n",
    "            parent[v] = parent[parent[v]]\n",
    "            v = parent[v]\n",
    "\n",
    "        return v\n",
    "\n",
    "    def union(a, b, new_bundle):\n",
    "        if a > b:\n",
    "            a, b = b, a\n",
    "\n",
    "        parent[b] = a\n",
    "        all_bundles[a] = new_bundle\n",
    "\n",
    "    for i in range(len(all_bundles)):\n",
    "        bundle = all_bundles[i]\n",
    "\n",
    "        shop_seq = bundle.shop_seq\n",
    "\n",
    "        xs_s_sum = 0\n",
    "        ys_s_sum = 0\n",
    "\n",
    "        xs_e_sum = 0\n",
    "        ys_e_sum = 0\n",
    "\n",
    "        readytimes_sum = 0\n",
    "        deadlines_sum = 0\n",
    "\n",
    "        shop_seq_len = len(shop_seq)\n",
    "\n",
    "        for order_num in shop_seq:\n",
    "            order = ALL_ORDERS[order_num]\n",
    "\n",
    "            xs_s_sum += order.shop_lat\n",
    "            ys_s_sum += order.shop_lon\n",
    "\n",
    "            xs_e_sum += order.dlv_lat\n",
    "            ys_e_sum += order.dlv_lon\n",
    "\n",
    "            readytimes_sum += order.ready_time\n",
    "            deadlines_sum += order.deadline\n",
    "\n",
    "        xs_s_avg = xs_s_sum / shop_seq_len\n",
    "        ys_s_avg = ys_s_sum / shop_seq_len\n",
    "\n",
    "        xs_e_avg = xs_e_sum / shop_seq_len\n",
    "        ys_e_avg = ys_e_sum / shop_seq_len\n",
    "\n",
    "        readytimes_avg = readytimes_sum / shop_seq_len\n",
    "        deadlines_avg = deadlines_sum / shop_seq_len\n",
    "\n",
    "        avg_info = [xs_s_avg, ys_s_avg, xs_e_avg, ys_e_avg, readytimes_avg, deadlines_avg]\n",
    "\n",
    "        bundle.avg_info = avg_info\n",
    "\n",
    "    edges = []\n",
    "    for i in range(len(all_bundles)):\n",
    "        for j in range(i + 1, len(all_bundles)):\n",
    "            avg_info1 = all_bundles[i].avg_info\n",
    "            avg_info2 = all_bundles[j].avg_info\n",
    "\n",
    "            sx1, sy1, ex1, ey1, r1, d1 = avg_info1\n",
    "            sx2, sy2, ex2, ey2, r2, d2 = avg_info2\n",
    "\n",
    "            r_diff = abs(r1 - r2)\n",
    "            d_diff = abs(d1 - d2)\n",
    "\n",
    "            start_end_diff = default_get_dist_function((sx1 + sx2) / 2, (sy1 + sy2) / 2, (ex1 + ex2) / 2, (ey1 + ey2) / 2)\n",
    "\n",
    "            if avg_method == 'avg':\n",
    "                dist1 = default_get_dist_function(sx1, sy1, sx2, sy2)\n",
    "                dist2 = default_get_dist_function(ex1, ey1, ex2, ey2)\n",
    "            elif avg_method == 'two_seq':\n",
    "                dist1 = DIST[i][j]\n",
    "                dist2 = DIST[i + K][j + K]\n",
    "            elif avg_method == 'two':\n",
    "                order_num1 = all_bundles[i].shop_seq[0]\n",
    "                order_num2 = all_bundles[j].shop_seq[0]\n",
    "\n",
    "                dist1 = DIST[order_num1][order_num2]\n",
    "                dist2 = DIST[order_num1 + K][order_num2 + K]  \n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "            # weight1 = (dist1 + dist2) / 900\n",
    "\n",
    "            # diff_score = dist1 + dist2 + r_diff * weight1 + d_diff * weight1 + start_end_diff * weight2\n",
    "            diff_score = dist1 + dist2 + r_diff * weight1 + d_diff * weight1 + start_end_diff * weight2\n",
    "\n",
    "            edges.append((i, j, diff_score))\n",
    "\n",
    "    parent = list(range(len(all_bundles)))\n",
    "    edges.sort(key=lambda x: x[2])\n",
    "\n",
    "    for bundle_num1, bundle_num2, diff_score in edges:\n",
    "        rbn1, rbn2 = find(bundle_num1), find(bundle_num2)\n",
    "\n",
    "        if rbn1 == rbn2:\n",
    "            continue\n",
    "\n",
    "        new_bundle = bundle_merging_function(K, DIST, ALL_ORDERS, ALL_RIDERS, all_bundles[rbn1], all_bundles[rbn2], order_count_upper_limit)\n",
    "\n",
    "        if new_bundle is not None:\n",
    "            all_bundles[rbn1].rider.available_number += 1\n",
    "            all_bundles[rbn2].rider.available_number += 1\n",
    "            \n",
    "            new_bundle.rider.available_number -= 1\n",
    "\n",
    "            union(rbn1, rbn2, new_bundle)\n",
    "\n",
    "    parent = [find(v) for v in parent]\n",
    "\n",
    "    result_bundles = [all_bundles[v] for v in set(parent)]\n",
    "    rider_availables = [rider.available_number for rider in ALL_RIDERS]\n",
    "\n",
    "    return result_bundles, rider_availables\n",
    "\n",
    "## --------------- 초기 번들링 최적화 코드 --------------------------\n",
    "\n",
    "weight1 = 1\n",
    "weight2 = -1\n",
    "\n",
    "avg_method = 'two'\n",
    "bundle_merging_function = try_merging_bundles_by_dist\n",
    "default_get_dist_function = get_dist_by_coords\n",
    "\n",
    "inf = float('inf')\n",
    "\n",
    "car_rider = [rider for rider in ALL_RIDERS if rider.type == 'CAR'][0]\n",
    "bike_rider = [rider for rider in ALL_RIDERS if rider.type == 'BIKE'][0]\n",
    "walk_rider = [rider for rider in ALL_RIDERS if rider.type == 'WALK'][0]\n",
    "\n",
    "all_bundles = []\n",
    "for ord in ALL_ORDERS:\n",
    "    new_bundle = Bundle(ALL_ORDERS, car_rider, [ord.id], [ord.id], ord.volume, DIST[ord.id, ord.id+K])\n",
    "    car_rider.available_number -= 1\n",
    "    all_bundles.append(new_bundle)\n",
    "\n",
    "# print('#2\\n')\n",
    "\n",
    "# 2개 주문 묶음 생성\n",
    "all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 2, 'two_seq', all_bundles, default_get_dist_function)\n",
    "\n",
    "# print('#4\\n')\n",
    "\n",
    "# 4개 주문 묶음 생성\n",
    "all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 4, 'avg', all_bundles, default_get_dist_function)\n",
    "\n",
    "# 2개 이하 주문이 묶인 번들을 전부 푼 다음 다시 생성\n",
    "new_all_bundles = []\n",
    "for bundle in all_bundles:\n",
    "    if len(bundle.shop_seq) >= 3:\n",
    "        new_all_bundles.append(bundle)\n",
    "    else:\n",
    "        old_rider = bundle.rider\n",
    "        old_rider.available_number += 1\n",
    "        for order_num in bundle.shop_seq:\n",
    "            order = ALL_ORDERS[order_num]\n",
    "\n",
    "            new_bundle = Bundle(ALL_ORDERS, car_rider, [order.id], [order.id], order.volume, DIST[order.id, order.id + K])\n",
    "            car_rider.available_number -= 1\n",
    "            new_all_bundles.append(new_bundle)\n",
    "\n",
    "# print('#remain\\n')\n",
    "\n",
    "all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 3, 'two', new_all_bundles, default_get_dist_function)\n",
    "\n",
    "## ------------------- 라이더 재배치 -------------------------------\n",
    "\n",
    "all_bundles, rider_availables = reassign_riders(K, ALL_ORDERS, ALL_RIDERS, DIST, init_availables, all_bundles)\n",
    "for rider_i in range(3):\n",
    "    ALL_RIDERS[rider_i].available_number = rider_availables[rider_i]\n",
    "\n",
    "## -------------- 솔루션 제작 및 실현 가능성 확인 코드 ---------------- \n",
    "\n",
    "solution = [\n",
    "        # rider type, shop_seq, dlv_seq\n",
    "        [bundle.rider.type, bundle.shop_seq, bundle.dlv_seq]\n",
    "        for bundle in all_bundles\n",
    "]\n",
    "\n",
    "with open(problem_file, 'r') as f:\n",
    "    prob = json.load(f)\n",
    "\n",
    "K = prob['K']\n",
    "\n",
    "ALL_ORDERS = [Order(order_info) for order_info in prob['ORDERS']]\n",
    "ALL_RIDERS = [Rider(rider_info) for rider_info in prob['RIDERS']]\n",
    "\n",
    "DIST = np.array(prob['DIST'])\n",
    "for r in ALL_RIDERS:\n",
    "    r.T = np.round(DIST/r.speed + r.service_time).astype(int)\n",
    "\n",
    "checked_solution = solution_check(K, ALL_ORDERS, ALL_RIDERS, DIST, solution)\n",
    "\n",
    "checked_solution['avg_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 17), (2, 9), (3, 3)],\n",
       " [(1, 8), (2, 14), (3, 7)],\n",
       " [(1, 4), (2, 6), (3, 19)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_order_bundles = [bundle for bundle in checked_solution['bundles'] if len(bundle[1]) == 3]\n",
    "\n",
    "ready_time_cts = [Counter() for _ in range(3)]\n",
    "deadline_cts = [Counter() for _ in range(3)]\n",
    "for bundle in three_order_bundles:\n",
    "    ready_times = []\n",
    "    deadlines = []\n",
    "    for order_num in bundle[1]:\n",
    "        order = ALL_ORDERS[order_num]\n",
    "\n",
    "        ready_times.append((order_num, order.ready_time))\n",
    "        deadlines.append((order_num, order.deadline))\n",
    "\n",
    "    ready_times.sort(key=lambda x: x[1])\n",
    "    deadlines.sort(key=lambda x: x[1])\n",
    "\n",
    "    ready_time_nths = [0] * 3\n",
    "    deadline_nths = [0] * 3\n",
    "\n",
    "    shop_seq = bundle[1]\n",
    "    dlv_seq = bundle[2]\n",
    "    for nth, (order_num, _) in enumerate(ready_times):\n",
    "        shop_index = shop_seq.index(order_num)\n",
    "        ready_time_nths[shop_index] = nth + 1\n",
    "\n",
    "        dlv_index = dlv_seq.index(order_num)\n",
    "        deadline_nths[dlv_index] = nth + 1\n",
    "\n",
    "    for i in range(3):\n",
    "        ready_time_cts[i][ready_time_nths[i]] += 1\n",
    "        deadline_cts[i][deadline_nths[i]] += 1\n",
    "\n",
    "    for i in range(3):\n",
    "        for nth in range(1, 4):\n",
    "            ready_time_cts[i][nth] += 0\n",
    "            deadline_cts[i][nth] += 0\n",
    "\n",
    "ready_time_freqs = [sorted(ct.items(), key=lambda x: x[0]) for ct in ready_time_cts]\n",
    "deadline_freqs = [sorted(ct.items(), key=lambda x: x[0]) for ct in deadline_cts]\n",
    "\n",
    "ready_time_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모든 테스트 케이스 대상으로 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_K50_1.json\n",
      "TEST_K50_2.json\n",
      "TEST_K100_1.json\n",
      "TEST_K100_2.json\n",
      "TEST_K200_1.json\n",
      "TEST_K200_2.json\n",
      "STAGE1_1.json\n",
      "STAGE1_2.json\n",
      "STAGE1_3.json\n",
      "STAGE1_4.json\n",
      "STAGE1_5.json\n",
      "STAGE1_6.json\n",
      "STAGE1_7.json\n",
      "STAGE1_8.json\n",
      "STAGE1_9.json\n",
      "STAGE1_10.json\n",
      "STAGE1_11.json\n",
      "STAGE1_12.json\n",
      "STAGE1_13.json\n",
      "STAGE1_14.json\n",
      "STAGE1_15.json\n",
      "STAGE1_16.json\n",
      "STAGE1_17.json\n",
      "STAGE1_18.json\n"
     ]
    }
   ],
   "source": [
    "# 기본 데이터셋 추가\n",
    "data_sizes = [50, 100, 200]\n",
    "problem_files = []\n",
    "for data_size in data_sizes:\n",
    "    problem_files.append(fr'C:\\Users\\hsh80\\Desktop\\LG CNS\\alg_test_problems_20240429\\TEST_K{data_size}_1.json')\n",
    "    problem_files.append(fr'C:\\Users\\hsh80\\Desktop\\LG CNS\\alg_test_problems_20240429\\TEST_K{data_size}_2.json')\n",
    "\n",
    "# stage 데이터 추가\n",
    "for file_num in range(1, 19):\n",
    "    problem_file = fr'C:\\Users\\hsh80\\Desktop\\LG CNS\\stage1_problems\\STAGE1_{file_num}.json'\n",
    "\n",
    "    problem_files.append(problem_file)\n",
    "\n",
    "results = []\n",
    "for problem_file in problem_files:\n",
    "    problem_file_name = problem_file.split('\\\\')[-1]\n",
    "\n",
    "    ## ------------------- 초기 상태 할당 코드 -------------------------\n",
    "\n",
    "    with open(problem_file, 'r') as f:\n",
    "        prob = json.load(f)\n",
    "\n",
    "    K = prob['K']\n",
    "\n",
    "    ALL_ORDERS = [Order(order_info) for order_info in prob['ORDERS']]\n",
    "    ALL_RIDERS = [Rider(rider_info) for rider_info in prob['RIDERS']]\n",
    "\n",
    "    DIST = np.array(prob['DIST'])\n",
    "    for r in ALL_RIDERS:\n",
    "        r.T = np.round(DIST/r.speed + r.service_time).astype(int)\n",
    "\n",
    "    inf = float('inf')\n",
    "\n",
    "    car_rider = [rider for rider in ALL_RIDERS if rider.type == 'CAR'][0]\n",
    "    bike_rider = [rider for rider in ALL_RIDERS if rider.type == 'BIKE'][0]\n",
    "    walk_rider = [rider for rider in ALL_RIDERS if rider.type == 'WALK'][0]\n",
    "\n",
    "    init_availables = [rider.available_number for rider in ALL_RIDERS]\n",
    "\n",
    "    ## ------------------  크루스칼 함수   -----------------------------\n",
    "\n",
    "    def kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, order_count_upper_limit, avg_method, all_bundles, default_get_dist_function):\n",
    "        def find(v):\n",
    "            while v != parent[v]:\n",
    "                parent[v] = parent[parent[v]]\n",
    "                v = parent[v]\n",
    "\n",
    "            return v\n",
    "\n",
    "        def union(a, b, new_bundle):\n",
    "            if a > b:\n",
    "                a, b = b, a\n",
    "\n",
    "            parent[b] = a\n",
    "            all_bundles[a] = new_bundle\n",
    "\n",
    "        for i in range(len(all_bundles)):\n",
    "            bundle = all_bundles[i]\n",
    "\n",
    "            shop_seq = bundle.shop_seq\n",
    "\n",
    "            xs_s_sum = 0\n",
    "            ys_s_sum = 0\n",
    "\n",
    "            xs_e_sum = 0\n",
    "            ys_e_sum = 0\n",
    "\n",
    "            readytimes_sum = 0\n",
    "            deadlines_sum = 0\n",
    "\n",
    "            shop_seq_len = len(shop_seq)\n",
    "\n",
    "            for order_num in shop_seq:\n",
    "                order = ALL_ORDERS[order_num]\n",
    "\n",
    "                xs_s_sum += order.shop_lat\n",
    "                ys_s_sum += order.shop_lon\n",
    "\n",
    "                xs_e_sum += order.dlv_lat\n",
    "                ys_e_sum += order.dlv_lon\n",
    "\n",
    "                readytimes_sum += order.ready_time\n",
    "                deadlines_sum += order.deadline\n",
    "\n",
    "            xs_s_avg = xs_s_sum / shop_seq_len\n",
    "            ys_s_avg = ys_s_sum / shop_seq_len\n",
    "\n",
    "            xs_e_avg = xs_e_sum / shop_seq_len\n",
    "            ys_e_avg = ys_e_sum / shop_seq_len\n",
    "\n",
    "            readytimes_avg = readytimes_sum / shop_seq_len\n",
    "            deadlines_avg = deadlines_sum / shop_seq_len\n",
    "\n",
    "            avg_info = [xs_s_avg, ys_s_avg, xs_e_avg, ys_e_avg, readytimes_avg, deadlines_avg]\n",
    "\n",
    "            bundle.avg_info = avg_info\n",
    "\n",
    "        edges = []\n",
    "        for i in range(len(all_bundles)):\n",
    "            for j in range(i + 1, len(all_bundles)):\n",
    "                avg_info1 = all_bundles[i].avg_info\n",
    "                avg_info2 = all_bundles[j].avg_info\n",
    "\n",
    "                sx1, sy1, ex1, ey1, r1, d1 = avg_info1\n",
    "                sx2, sy2, ex2, ey2, r2, d2 = avg_info2\n",
    "\n",
    "                r_diff = abs(r1 - r2)\n",
    "                d_diff = abs(d1 - d2)\n",
    "\n",
    "                start_end_diff = default_get_dist_function((sx1 + sx2) / 2, (sy1 + sy2) / 2, (ex1 + ex2) / 2, (ey1 + ey2) / 2)\n",
    "\n",
    "                if avg_method == 'avg':\n",
    "                    dist1 = default_get_dist_function(sx1, sy1, sx2, sy2)\n",
    "                    dist2 = default_get_dist_function(ex1, ey1, ex2, ey2)\n",
    "                elif avg_method == 'two_seq':\n",
    "                    dist1 = DIST[i][j]\n",
    "                    dist2 = DIST[i + K][j + K]\n",
    "                elif avg_method == 'two':\n",
    "                    order_num1 = all_bundles[i].shop_seq[0]\n",
    "                    order_num2 = all_bundles[j].shop_seq[0]\n",
    "\n",
    "                    dist1 = DIST[order_num1][order_num2]\n",
    "                    dist2 = DIST[order_num1 + K][order_num2 + K]  \n",
    "                else:\n",
    "                    assert False\n",
    "\n",
    "                # weight1 = (dist1 + dist2) / 900\n",
    "\n",
    "                # diff_score = dist1 + dist2 + r_diff * weight1 + d_diff * weight1 + start_end_diff * weight2\n",
    "                diff_score = dist1 + dist2 + r_diff * weight1 + d_diff * weight1 + start_end_diff * weight2\n",
    "\n",
    "                edges.append((i, j, diff_score))\n",
    "\n",
    "        parent = list(range(len(all_bundles)))\n",
    "        edges.sort(key=lambda x: x[2])\n",
    "\n",
    "        for bundle_num1, bundle_num2, diff_score in edges:\n",
    "            rbn1, rbn2 = find(bundle_num1), find(bundle_num2)\n",
    "\n",
    "            if rbn1 == rbn2:\n",
    "                continue\n",
    "\n",
    "            new_bundle = bundle_merging_function(K, DIST, ALL_ORDERS, ALL_RIDERS, all_bundles[rbn1], all_bundles[rbn2], order_count_upper_limit)\n",
    "\n",
    "            if new_bundle is not None:\n",
    "                all_bundles[rbn1].rider.available_number += 1\n",
    "                all_bundles[rbn2].rider.available_number += 1\n",
    "                \n",
    "                new_bundle.rider.available_number -= 1\n",
    "\n",
    "                union(rbn1, rbn2, new_bundle)\n",
    "\n",
    "        parent = [find(v) for v in parent]\n",
    "\n",
    "        result_bundles = [all_bundles[v] for v in set(parent)]\n",
    "        rider_availables = [rider.available_number for rider in ALL_RIDERS]\n",
    "\n",
    "        return result_bundles, rider_availables\n",
    "\n",
    "    ## --------------- 초기 번들링 최적화 코드 --------------------------\n",
    "\n",
    "    weight1 = 1\n",
    "    weight2 = 0\n",
    "\n",
    "    avg_method = 'two'\n",
    "    bundle_merging_function = try_merging_bundles_by_dist\n",
    "    default_get_dist_function = get_dist_by_coords\n",
    "\n",
    "    inf = float('inf')\n",
    "\n",
    "    car_rider = [rider for rider in ALL_RIDERS if rider.type == 'CAR'][0]\n",
    "    bike_rider = [rider for rider in ALL_RIDERS if rider.type == 'BIKE'][0]\n",
    "    walk_rider = [rider for rider in ALL_RIDERS if rider.type == 'WALK'][0]\n",
    "\n",
    "    all_bundles = []\n",
    "    for ord in ALL_ORDERS:\n",
    "        new_bundle = Bundle(ALL_ORDERS, car_rider, [ord.id], [ord.id], ord.volume, DIST[ord.id, ord.id+K])\n",
    "        car_rider.available_number -= 1\n",
    "        all_bundles.append(new_bundle)\n",
    "\n",
    "    # print('#2\\n')\n",
    "\n",
    "    # 2개 주문 묶음 생성\n",
    "    all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 2, 'two_seq', all_bundles, default_get_dist_function)\n",
    "\n",
    "    # print('#4\\n')\n",
    "\n",
    "    # 4개 주문 묶음 생성\n",
    "    all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 4, 'avg', all_bundles, default_get_dist_function)\n",
    "\n",
    "    # 2개 이하 주문이 묶인 번들을 전부 푼 다음 다시 생성\n",
    "    new_all_bundles = []\n",
    "    for bundle in all_bundles:\n",
    "        if len(bundle.shop_seq) >= 3:\n",
    "            new_all_bundles.append(bundle)\n",
    "        else:\n",
    "            old_rider = bundle.rider\n",
    "            old_rider.available_number += 1\n",
    "            for order_num in bundle.shop_seq:\n",
    "                order = ALL_ORDERS[order_num]\n",
    "\n",
    "                new_bundle = Bundle(ALL_ORDERS, car_rider, [order.id], [order.id], order.volume, DIST[order.id, order.id + K])\n",
    "                car_rider.available_number -= 1\n",
    "                new_all_bundles.append(new_bundle)\n",
    "\n",
    "    # print('#remain\\n')\n",
    "\n",
    "    all_bundles, rider_availables = kruskal_bundling(K, DIST, ALL_ORDERS, ALL_RIDERS, weight1, weight2, bundle_merging_function, 3, 'two', new_all_bundles, default_get_dist_function)\n",
    "\n",
    "    ## ------------------- 라이더 재배치 -------------------------------\n",
    "\n",
    "    all_bundles, rider_availables = reassign_riders(K, ALL_ORDERS, ALL_RIDERS, DIST, init_availables, all_bundles)\n",
    "    for rider_i in range(3):\n",
    "        ALL_RIDERS[rider_i].available_number = rider_availables[rider_i]\n",
    "\n",
    "    ## -------------- 솔루션 제작 및 실현 가능성 확인 코드 ---------------- \n",
    "\n",
    "    solution = [\n",
    "            # rider type, shop_seq, dlv_seq\n",
    "            [bundle.rider.type, bundle.shop_seq, bundle.dlv_seq]\n",
    "            for bundle in all_bundles\n",
    "    ]\n",
    "\n",
    "    with open(problem_file, 'r') as f:\n",
    "        prob = json.load(f)\n",
    "\n",
    "    K = prob['K']\n",
    "\n",
    "    ALL_ORDERS = [Order(order_info) for order_info in prob['ORDERS']]\n",
    "    ALL_RIDERS = [Rider(rider_info) for rider_info in prob['RIDERS']]\n",
    "\n",
    "    DIST = np.array(prob['DIST'])\n",
    "    for r in ALL_RIDERS:\n",
    "        r.T = np.round(DIST/r.speed + r.service_time).astype(int)\n",
    "\n",
    "    checked_solution = solution_check(K, ALL_ORDERS, ALL_RIDERS, DIST, solution)\n",
    "\n",
    "    three_order_bundles = [bundle for bundle in checked_solution['bundles'] if len(bundle[1]) == 3]\n",
    "\n",
    "    ready_time_cts = [Counter() for _ in range(3)]\n",
    "    deadline_cts = [Counter() for _ in range(3)]\n",
    "    for bundle in three_order_bundles:\n",
    "        ready_times = []\n",
    "        deadlines = []\n",
    "        for order_num in bundle[1]:\n",
    "            order = ALL_ORDERS[order_num]\n",
    "\n",
    "            ready_times.append((order_num, order.ready_time))\n",
    "            deadlines.append((order_num, order.deadline))\n",
    "\n",
    "        ready_times.sort(key=lambda x: x[1])\n",
    "        deadlines.sort(key=lambda x: x[1])\n",
    "\n",
    "        ready_time_nths = [0] * 3\n",
    "        deadline_nths = [0] * 3\n",
    "\n",
    "        shop_seq = bundle[1]\n",
    "        dlv_seq = bundle[2]\n",
    "        for nth, (order_num, _) in enumerate(ready_times):\n",
    "            shop_index = shop_seq.index(order_num)\n",
    "            ready_time_nths[shop_index] = nth + 1\n",
    "\n",
    "            dlv_index = dlv_seq.index(order_num)\n",
    "            deadline_nths[dlv_index] = nth + 1\n",
    "\n",
    "        for i in range(3):\n",
    "            ready_time_cts[i][ready_time_nths[i]] += 1\n",
    "            deadline_cts[i][deadline_nths[i]] += 1\n",
    "\n",
    "        for i in range(3):\n",
    "            for nth in range(1, 4):\n",
    "                ready_time_cts[i][nth] += 0\n",
    "                deadline_cts[i][nth] += 0\n",
    "\n",
    "    ready_time_freqs = [sorted(ct.items(), key=lambda x: x[0]) for ct in ready_time_cts]\n",
    "    deadline_freqs = [sorted(ct.items(), key=lambda x: x[0]) for ct in deadline_cts]\n",
    "\n",
    "    results.append((problem_file_name, K, ready_time_freqs, deadline_freqs))\n",
    "\n",
    "    print(problem_file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['TEST_K50_1.json',\n",
       "  50,\n",
       "  [[(1, 3), (2, 5), (3, 1)],\n",
       "   [(1, 3), (2, 2), (3, 4)],\n",
       "   [(1, 3), (2, 2), (3, 4)]]],\n",
       " ['TEST_K50_2.json',\n",
       "  50,\n",
       "  [[(1, 4), (2, 3), (3, 1)],\n",
       "   [(1, 4), (2, 4), (3, 0)],\n",
       "   [(1, 0), (2, 1), (3, 7)]]],\n",
       " ['TEST_K100_1.json',\n",
       "  100,\n",
       "  [[(1, 7), (2, 5), (3, 1)],\n",
       "   [(1, 3), (2, 4), (3, 6)],\n",
       "   [(1, 3), (2, 4), (3, 6)]]],\n",
       " ['TEST_K100_2.json',\n",
       "  100,\n",
       "  [[(1, 13), (2, 3), (3, 1)],\n",
       "   [(1, 3), (2, 8), (3, 6)],\n",
       "   [(1, 1), (2, 6), (3, 10)]]],\n",
       " ['TEST_K200_1.json',\n",
       "  200,\n",
       "  [[(1, 22), (2, 7), (3, 2)],\n",
       "   [(1, 7), (2, 14), (3, 10)],\n",
       "   [(1, 2), (2, 10), (3, 19)]]],\n",
       " ['TEST_K200_2.json',\n",
       "  200,\n",
       "  [[(1, 19), (2, 7), (3, 4)],\n",
       "   [(1, 4), (2, 17), (3, 9)],\n",
       "   [(1, 7), (2, 6), (3, 17)]]],\n",
       " ['STAGE1_1.json',\n",
       "  100,\n",
       "  [[(1, 5), (2, 7), (3, 1)],\n",
       "   [(1, 3), (2, 5), (3, 5)],\n",
       "   [(1, 5), (2, 1), (3, 7)]]],\n",
       " ['STAGE1_2.json',\n",
       "  100,\n",
       "  [[(1, 2), (2, 3), (3, 3)],\n",
       "   [(1, 2), (2, 1), (3, 5)],\n",
       "   [(1, 4), (2, 4), (3, 0)]]],\n",
       " ['STAGE1_3.json',\n",
       "  200,\n",
       "  [[(1, 16), (2, 6), (3, 1)],\n",
       "   [(1, 5), (2, 13), (3, 5)],\n",
       "   [(1, 2), (2, 4), (3, 17)]]],\n",
       " ['STAGE1_4.json',\n",
       "  200,\n",
       "  [[(1, 5), (2, 5), (3, 4)],\n",
       "   [(1, 5), (2, 3), (3, 6)],\n",
       "   [(1, 4), (2, 6), (3, 4)]]],\n",
       " ['STAGE1_5.json',\n",
       "  300,\n",
       "  [[(1, 7), (2, 5), (3, 5)],\n",
       "   [(1, 4), (2, 9), (3, 4)],\n",
       "   [(1, 6), (2, 3), (3, 8)]]],\n",
       " ['STAGE1_6.json',\n",
       "  300,\n",
       "  [[(1, 3), (2, 3), (3, 5)],\n",
       "   [(1, 6), (2, 3), (3, 2)],\n",
       "   [(1, 2), (2, 5), (3, 4)]]],\n",
       " ['STAGE1_7.json',\n",
       "  100,\n",
       "  [[(1, 5), (2, 5), (3, 1)],\n",
       "   [(1, 5), (2, 4), (3, 2)],\n",
       "   [(1, 1), (2, 2), (3, 8)]]],\n",
       " ['STAGE1_8.json',\n",
       "  100,\n",
       "  [[(1, 5), (2, 2), (3, 0)],\n",
       "   [(1, 2), (2, 3), (3, 2)],\n",
       "   [(1, 0), (2, 2), (3, 5)]]],\n",
       " ['STAGE1_9.json',\n",
       "  200,\n",
       "  [[(1, 20), (2, 13), (3, 3)],\n",
       "   [(1, 11), (2, 15), (3, 10)],\n",
       "   [(1, 5), (2, 8), (3, 23)]]],\n",
       " ['STAGE1_10.json',\n",
       "  200,\n",
       "  [[(1, 2), (2, 2), (3, 0)],\n",
       "   [(1, 1), (2, 2), (3, 1)],\n",
       "   [(1, 1), (2, 0), (3, 3)]]],\n",
       " ['STAGE1_11.json',\n",
       "  300,\n",
       "  [[(1, 22), (2, 13), (3, 5)],\n",
       "   [(1, 8), (2, 16), (3, 16)],\n",
       "   [(1, 10), (2, 11), (3, 19)]]],\n",
       " ['STAGE1_12.json',\n",
       "  300,\n",
       "  [[(1, 6), (2, 3), (3, 2)],\n",
       "   [(1, 4), (2, 4), (3, 3)],\n",
       "   [(1, 1), (2, 4), (3, 6)]]],\n",
       " ['STAGE1_13.json',\n",
       "  100,\n",
       "  [[(1, 4), (2, 4), (3, 3)],\n",
       "   [(1, 5), (2, 4), (3, 2)],\n",
       "   [(1, 2), (2, 3), (3, 6)]]],\n",
       " ['STAGE1_14.json',\n",
       "  100,\n",
       "  [[(1, 8), (2, 1), (3, 1)],\n",
       "   [(1, 2), (2, 5), (3, 3)],\n",
       "   [(1, 0), (2, 4), (3, 6)]]],\n",
       " ['STAGE1_15.json',\n",
       "  200,\n",
       "  [[(1, 22), (2, 5), (3, 4)],\n",
       "   [(1, 6), (2, 20), (3, 5)],\n",
       "   [(1, 3), (2, 6), (3, 22)]]],\n",
       " ['STAGE1_16.json',\n",
       "  200,\n",
       "  [[(1, 4), (2, 5), (3, 6)],\n",
       "   [(1, 6), (2, 4), (3, 5)],\n",
       "   [(1, 5), (2, 6), (3, 4)]]],\n",
       " ['STAGE1_17.json',\n",
       "  300,\n",
       "  [[(1, 26), (2, 12), (3, 3)],\n",
       "   [(1, 11), (2, 15), (3, 15)],\n",
       "   [(1, 4), (2, 14), (3, 23)]]],\n",
       " ['STAGE1_18.json',\n",
       "  300,\n",
       "  [[(1, 5), (2, 3), (3, 2)],\n",
       "   [(1, 4), (2, 4), (3, 2)],\n",
       "   [(1, 1), (2, 3), (3, 6)]]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[v[0], v[1], v[2]] for v in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['TEST_K50_1.json',\n",
       "  50,\n",
       "  [[(1, 6), (2, 1), (3, 2)],\n",
       "   [(1, 2), (2, 5), (3, 2)],\n",
       "   [(1, 1), (2, 3), (3, 5)]]],\n",
       " ['TEST_K50_2.json',\n",
       "  50,\n",
       "  [[(1, 3), (2, 3), (3, 2)],\n",
       "   [(1, 3), (2, 4), (3, 1)],\n",
       "   [(1, 2), (2, 1), (3, 5)]]],\n",
       " ['TEST_K100_1.json',\n",
       "  100,\n",
       "  [[(1, 6), (2, 2), (3, 5)],\n",
       "   [(1, 3), (2, 7), (3, 3)],\n",
       "   [(1, 4), (2, 4), (3, 5)]]],\n",
       " ['TEST_K100_2.json',\n",
       "  100,\n",
       "  [[(1, 6), (2, 4), (3, 7)],\n",
       "   [(1, 9), (2, 5), (3, 3)],\n",
       "   [(1, 2), (2, 8), (3, 7)]]],\n",
       " ['TEST_K200_1.json',\n",
       "  200,\n",
       "  [[(1, 11), (2, 14), (3, 6)],\n",
       "   [(1, 14), (2, 11), (3, 6)],\n",
       "   [(1, 6), (2, 6), (3, 19)]]],\n",
       " ['TEST_K200_2.json',\n",
       "  200,\n",
       "  [[(1, 16), (2, 8), (3, 6)],\n",
       "   [(1, 8), (2, 15), (3, 7)],\n",
       "   [(1, 6), (2, 7), (3, 17)]]],\n",
       " ['STAGE1_1.json',\n",
       "  100,\n",
       "  [[(1, 6), (2, 6), (3, 1)],\n",
       "   [(1, 5), (2, 3), (3, 5)],\n",
       "   [(1, 2), (2, 4), (3, 7)]]],\n",
       " ['STAGE1_2.json',\n",
       "  100,\n",
       "  [[(1, 4), (2, 2), (3, 2)],\n",
       "   [(1, 4), (2, 1), (3, 3)],\n",
       "   [(1, 0), (2, 5), (3, 3)]]],\n",
       " ['STAGE1_3.json',\n",
       "  200,\n",
       "  [[(1, 10), (2, 7), (3, 6)],\n",
       "   [(1, 10), (2, 12), (3, 1)],\n",
       "   [(1, 3), (2, 4), (3, 16)]]],\n",
       " ['STAGE1_4.json',\n",
       "  200,\n",
       "  [[(1, 6), (2, 5), (3, 3)],\n",
       "   [(1, 4), (2, 8), (3, 2)],\n",
       "   [(1, 4), (2, 1), (3, 9)]]],\n",
       " ['STAGE1_5.json',\n",
       "  300,\n",
       "  [[(1, 6), (2, 9), (3, 2)],\n",
       "   [(1, 8), (2, 6), (3, 3)],\n",
       "   [(1, 3), (2, 2), (3, 12)]]],\n",
       " ['STAGE1_6.json',\n",
       "  300,\n",
       "  [[(1, 5), (2, 2), (3, 4)],\n",
       "   [(1, 3), (2, 7), (3, 1)],\n",
       "   [(1, 3), (2, 2), (3, 6)]]],\n",
       " ['STAGE1_7.json',\n",
       "  100,\n",
       "  [[(1, 7), (2, 3), (3, 1)],\n",
       "   [(1, 2), (2, 5), (3, 4)],\n",
       "   [(1, 2), (2, 3), (3, 6)]]],\n",
       " ['STAGE1_8.json',\n",
       "  100,\n",
       "  [[(1, 3), (2, 1), (3, 3)],\n",
       "   [(1, 3), (2, 3), (3, 1)],\n",
       "   [(1, 1), (2, 3), (3, 3)]]],\n",
       " ['STAGE1_9.json',\n",
       "  200,\n",
       "  [[(1, 14), (2, 11), (3, 11)],\n",
       "   [(1, 11), (2, 11), (3, 14)],\n",
       "   [(1, 11), (2, 14), (3, 11)]]],\n",
       " ['STAGE1_10.json',\n",
       "  200,\n",
       "  [[(1, 1), (2, 3), (3, 0)],\n",
       "   [(1, 1), (2, 1), (3, 2)],\n",
       "   [(1, 2), (2, 0), (3, 2)]]],\n",
       " ['STAGE1_11.json',\n",
       "  300,\n",
       "  [[(1, 18), (2, 14), (3, 8)],\n",
       "   [(1, 13), (2, 18), (3, 9)],\n",
       "   [(1, 9), (2, 8), (3, 23)]]],\n",
       " ['STAGE1_12.json',\n",
       "  300,\n",
       "  [[(1, 6), (2, 1), (3, 4)],\n",
       "   [(1, 1), (2, 6), (3, 4)],\n",
       "   [(1, 4), (2, 4), (3, 3)]]],\n",
       " ['STAGE1_13.json',\n",
       "  100,\n",
       "  [[(1, 5), (2, 3), (3, 3)],\n",
       "   [(1, 4), (2, 5), (3, 2)],\n",
       "   [(1, 2), (2, 3), (3, 6)]]],\n",
       " ['STAGE1_14.json',\n",
       "  100,\n",
       "  [[(1, 3), (2, 3), (3, 4)],\n",
       "   [(1, 2), (2, 4), (3, 4)],\n",
       "   [(1, 5), (2, 3), (3, 2)]]],\n",
       " ['STAGE1_15.json',\n",
       "  200,\n",
       "  [[(1, 14), (2, 8), (3, 9)],\n",
       "   [(1, 8), (2, 15), (3, 8)],\n",
       "   [(1, 9), (2, 8), (3, 14)]]],\n",
       " ['STAGE1_16.json',\n",
       "  200,\n",
       "  [[(1, 7), (2, 5), (3, 3)],\n",
       "   [(1, 4), (2, 5), (3, 6)],\n",
       "   [(1, 4), (2, 5), (3, 6)]]],\n",
       " ['STAGE1_17.json',\n",
       "  300,\n",
       "  [[(1, 16), (2, 14), (3, 11)],\n",
       "   [(1, 18), (2, 19), (3, 4)],\n",
       "   [(1, 7), (2, 8), (3, 26)]]],\n",
       " ['STAGE1_18.json',\n",
       "  300,\n",
       "  [[(1, 6), (2, 2), (3, 2)],\n",
       "   [(1, 2), (2, 6), (3, 2)],\n",
       "   [(1, 2), (2, 2), (3, 6)]]]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[v[0], v[1], v[3]] for v in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 2, 1)\n",
      "(4, 3, 1, 2)\n",
      "(4, 2, 3, 1)\n",
      "(4, 2, 1, 3)\n",
      "(4, 1, 3, 2)\n",
      "(4, 1, 2, 3)\n",
      "(3, 4, 2, 1)\n",
      "(3, 4, 1, 2)\n",
      "(3, 2, 4, 1)\n",
      "(3, 2, 1, 4)\n",
      "(3, 1, 4, 2)\n",
      "(3, 1, 2, 4)\n",
      "(2, 4, 3, 1)\n",
      "(2, 4, 1, 3)\n",
      "(2, 3, 4, 1)\n",
      "(2, 3, 1, 4)\n",
      "(2, 1, 4, 3)\n",
      "(2, 1, 3, 4)\n",
      "(1, 4, 3, 2)\n",
      "(1, 4, 2, 3)\n",
      "(1, 3, 4, 2)\n",
      "(1, 3, 2, 4)\n",
      "(1, 2, 4, 3)\n",
      "(1, 2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "li = [4, 3, 2, 1]\n",
    "for case in permutations(li):\n",
    "    print(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
